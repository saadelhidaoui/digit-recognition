{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('data/train.csv')\n",
    "test_dataset = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(train_dataset.isnull().sum().sum())\n",
    "print(test_dataset.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = train_dataset.drop(columns=['label']).values\n",
    "y = train_dataset['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values\n",
    "X = X / 255.0\n",
    "test_data = test_dataset.values / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to fit the model input (28x28x1)\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "test_data = test_data.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical format\n",
    "y = to_categorical(y, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "index = 3\n",
    "sample_image = X[index]\n",
    "sample_label = y[index]\n",
    "\n",
    "sample_image = sample_image.squeeze()  # Shape becomes (28, 28)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(sample_image, cmap='gray')\n",
    "plt.title(f'Label: {sample_label}')\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "525/525 [==============================] - 18s 31ms/step - loss: 0.3195 - accuracy: 0.9021 - val_loss: 0.1277 - val_accuracy: 0.9590\n",
      "Epoch 2/25\n",
      "525/525 [==============================] - 17s 33ms/step - loss: 0.1029 - accuracy: 0.9674 - val_loss: 0.0882 - val_accuracy: 0.9721\n",
      "Epoch 3/25\n",
      "525/525 [==============================] - 17s 32ms/step - loss: 0.0696 - accuracy: 0.9772 - val_loss: 0.0718 - val_accuracy: 0.9777\n",
      "Epoch 4/25\n",
      "525/525 [==============================] - 21s 40ms/step - loss: 0.0561 - accuracy: 0.9816 - val_loss: 0.0675 - val_accuracy: 0.9792\n",
      "Epoch 5/25\n",
      "525/525 [==============================] - 19s 36ms/step - loss: 0.0460 - accuracy: 0.9860 - val_loss: 0.0572 - val_accuracy: 0.9831\n",
      "Epoch 6/25\n",
      "525/525 [==============================] - 23s 43ms/step - loss: 0.0363 - accuracy: 0.9885 - val_loss: 0.0572 - val_accuracy: 0.9830\n",
      "Epoch 7/25\n",
      "525/525 [==============================] - 24s 45ms/step - loss: 0.0305 - accuracy: 0.9900 - val_loss: 0.0498 - val_accuracy: 0.9848\n",
      "Epoch 8/25\n",
      "525/525 [==============================] - 17s 33ms/step - loss: 0.0256 - accuracy: 0.9916 - val_loss: 0.0596 - val_accuracy: 0.9814\n",
      "Epoch 9/25\n",
      "525/525 [==============================] - 16s 31ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.0602 - val_accuracy: 0.9823\n",
      "Epoch 10/25\n",
      "525/525 [==============================] - 18s 35ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.0888 - val_accuracy: 0.9764\n",
      "Epoch 11/25\n",
      "525/525 [==============================] - 19s 35ms/step - loss: 0.0168 - accuracy: 0.9941 - val_loss: 0.0498 - val_accuracy: 0.9863\n",
      "Epoch 12/25\n",
      "525/525 [==============================] - 23s 44ms/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 0.0638 - val_accuracy: 0.9831\n",
      "Epoch 13/25\n",
      "525/525 [==============================] - 19s 36ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.0682 - val_accuracy: 0.9839\n",
      "Epoch 14/25\n",
      "525/525 [==============================] - 22s 41ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.0572 - val_accuracy: 0.9880\n",
      "Epoch 15/25\n",
      "525/525 [==============================] - 18s 34ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0877 - val_accuracy: 0.9801\n",
      "Epoch 16/25\n",
      "525/525 [==============================] - 19s 37ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0660 - val_accuracy: 0.9857\n",
      "Epoch 17/25\n",
      "525/525 [==============================] - 23s 45ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0750 - val_accuracy: 0.9835\n",
      "Epoch 18/25\n",
      "525/525 [==============================] - 24s 46ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0605 - val_accuracy: 0.9860\n",
      "Epoch 19/25\n",
      "525/525 [==============================] - 26s 50ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0708 - val_accuracy: 0.9865\n",
      "Epoch 20/25\n",
      "525/525 [==============================] - 27s 51ms/step - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.0664 - val_accuracy: 0.9852\n",
      "Epoch 21/25\n",
      "525/525 [==============================] - 24s 46ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0609 - val_accuracy: 0.9858\n",
      "Epoch 22/25\n",
      "525/525 [==============================] - 24s 45ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0673 - val_accuracy: 0.9851\n",
      "Epoch 23/25\n",
      "525/525 [==============================] - 23s 44ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0718 - val_accuracy: 0.9851\n",
      "Epoch 24/25\n",
      "525/525 [==============================] - 22s 41ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0676 - val_accuracy: 0.9868\n",
      "Epoch 25/25\n",
      "525/525 [==============================] - 25s 47ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.0666 - val_accuracy: 0.9863\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=25,\n",
    "                    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 2s 9ms/step - loss: 0.0666 - accuracy: 0.9863\n",
      "Validation Loss: 0.0666, Validation Accuracy: 0.9863\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 8s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "test_predictions = model.predict(test_data)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ImageId': np.arange(1, len(test_predictions) + 1), 'Label': test_predictions})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
